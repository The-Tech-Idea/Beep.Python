{% extends "base.html" %}

{% block title %}Hardware Acceleration - LLM Management{% endblock %}

{% block content %}
<div class="d-flex justify-content-between flex-wrap flex-md-nowrap align-items-center pt-3 pb-2 mb-3 border-bottom">
    <h1 class="h2"><i class="bi bi-gpu-card me-2"></i>Hardware Acceleration</h1>
    <div class="btn-toolbar mb-2 mb-md-0">
        <button type="button" class="btn btn-outline-secondary me-2" onclick="detectHardware()">
            <i class="bi bi-arrow-clockwise me-1"></i>Refresh Detection
        </button>
    </div>
</div>

<!-- Status Alert -->
<div id="statusAlert" class="alert d-none" role="alert"></div>

<!-- Hardware Overview -->
<div class="row mb-4">
    <div class="col-md-3">
        <div class="card bg-dark border-success">
            <div class="card-body text-center">
                <h5 class="card-title text-success"><i class="bi bi-check-circle-fill"></i></h5>
                <h3 id="currentBackendDisplay">{{ active_backend|upper if active_backend else 'CPU' }}</h3>
                <p class="card-text text-muted">Active Backend</p>
            </div>
        </div>
    </div>
    <div class="col-md-3">
        <div class="card bg-dark border-info">
            <div class="card-body text-center">
                <h5 class="card-title text-info"><i class="bi bi-stars"></i></h5>
                <h3 id="recommendedBackendDisplay">{{ recommended_backend|upper if recommended_backend else 'CPU' }}</h3>
                <p class="card-text text-muted">Recommended</p>
            </div>
        </div>
    </div>
    <div class="col-md-3">
        <div class="card bg-dark border-warning">
            <div class="card-body text-center">
                <h5 class="card-title text-warning"><i class="bi bi-cpu"></i></h5>
                <h3>{{ profile.cpu_cores }}</h3>
                <p class="card-text text-muted">CPU Cores</p>
            </div>
        </div>
    </div>
    <div class="col-md-3">
        <div class="card bg-dark border-primary">
            <div class="card-body text-center">
                <h5 class="card-title text-primary"><i class="bi bi-memory"></i></h5>
                <h3>{{ "%.1f"|format(profile.ram_total / (1024**3)) }} GB</h3>
                <p class="card-text text-muted">System RAM</p>
            </div>
        </div>
    </div>
</div>

<!-- System Information -->
<div class="card bg-dark mb-4">
    <div class="card-header">
        <h5 class="mb-0"><i class="bi bi-pc-display me-2"></i>System Information</h5>
    </div>
    <div class="card-body">
        <div class="row">
            <div class="col-md-6">
                <table class="table table-dark table-borderless">
                    <tr><td class="text-muted">Operating System</td><td>{{ profile.os_name }} {{ profile.os_version[:30] }}...</td></tr>
                    <tr><td class="text-muted">Architecture</td><td>{{ profile.architecture }}</td></tr>
                    <tr><td class="text-muted">CPU</td><td>{{ profile.cpu_name }}</td></tr>
                </table>
            </div>
            <div class="col-md-6">
                <table class="table table-dark table-borderless">
                    <tr><td class="text-muted">RAM Available</td><td>{{ "%.1f"|format(profile.ram_available / (1024**3)) }} GB / {{ "%.1f"|format(profile.ram_total / (1024**3)) }} GB</td></tr>
                    <tr><td class="text-muted">llama-cpp-python</td><td>
                        {% if profile.llama_cpp_installed %}
                        <span class="badge bg-success">Installed</span> {{ profile.llama_cpp_version }}
                        {% else %}
                        <span class="badge bg-warning">Not Installed</span>
                        {% endif %}
                    </td></tr>
                </table>
            </div>
        </div>
    </div>
</div>

<div class="row">
    <!-- Available Backends -->
    <div class="col-md-6">
        <div class="card bg-dark mb-4">
            <div class="card-header">
                <h5 class="mb-0"><i class="bi bi-lightning-charge me-2"></i>Available Backends</h5>
            </div>
            <div class="card-body">
                <div id="backendsContainer">
                    {% for backend in profile.backends %}
                    <div class="backend-item p-3 mb-2 rounded {{ 'border border-success' if backend.available else 'border border-secondary' }} {{ 'bg-success bg-opacity-10' if active_backend == backend.type else '' }}" 
                         data-backend="{{ backend.type }}">
                        <div class="d-flex justify-content-between align-items-center">
                            <div>
                                <h6 class="mb-1">
                                    {% if backend.type == 'cuda' %}
                                    <i class="bi bi-gpu-card me-2 text-success"></i>
                                    {% elif backend.type == 'rocm' %}
                                    <i class="bi bi-gpu-card me-2 text-danger"></i>
                                    {% elif backend.type == 'vulkan' %}
                                    <i class="bi bi-gpu-card me-2 text-warning"></i>
                                    {% elif backend.type == 'metal' %}
                                    <i class="bi bi-apple me-2 text-light"></i>
                                    {% elif backend.type == 'openblas' %}
                                    <i class="bi bi-speedometer2 me-2 text-info"></i>
                                    {% else %}
                                    <i class="bi bi-cpu me-2 text-info"></i>
                                    {% endif %}
                                    {{ backend.name }}
                                    {% if backend.recommended %}
                                    <span class="badge bg-success ms-2">Recommended</span>
                                    {% endif %}
                                    {% if active_backend == backend.type %}
                                    <span class="badge bg-primary ms-2">Active</span>
                                    {% endif %}
                                </h6>
                                <small class="text-muted">{{ backend.description }}</small>
                                {% if backend.available %}
                                <div class="mt-1">
                                    <span class="text-success"><i class="bi bi-check-circle"></i> Available</span>
                                    {% if backend.devices %}
                                    - {{ backend.devices|length }} device(s)
                                    {% endif %}
                                </div>
                                {% else %}
                                <div class="mt-1">
                                    <span class="text-secondary"><i class="bi bi-x-circle"></i> Not detected</span>
                                </div>
                                {% endif %}
                            </div>
                            <div>
                                {% if backend.available %}
                                <button class="btn btn-sm {{ 'btn-success' if active_backend == backend.type else 'btn-outline-success' }}" 
                                        onclick="selectBackend('{{ backend.type }}')"
                                        {% if active_backend == backend.type %}disabled{% endif %}>
                                    {% if active_backend == backend.type %}Active{% else %}Select{% endif %}
                                </button>
                                {% else %}
                                <button class="btn btn-sm btn-outline-secondary" disabled>
                                    Unavailable
                                </button>
                                {% endif %}
                            </div>
                        </div>
                    </div>
                    {% endfor %}
                </div>
            </div>
        </div>
    </div>

    <!-- GPU Information -->
    <div class="col-md-6">
        <div class="card bg-dark mb-4">
            <div class="card-header">
                <h5 class="mb-0"><i class="bi bi-gpu-card me-2"></i>GPU Devices</h5>
            </div>
            <div class="card-body">
                <div id="gpuContainer">
                    {% set gpu_found = false %}
                    {% for backend in profile.backends %}
                    {% if backend.devices %}
                    {% set gpu_found = true %}
                    {% for device in backend.devices %}
                    <div class="gpu-item p-3 mb-2 rounded border border-info">
                        <div class="d-flex justify-content-between align-items-start">
                            <div>
                                <h6 class="mb-1">{{ device.name }}</h6>
                                <small class="text-muted">
                                    <i class="bi bi-memory me-1"></i>{{ "%.1f"|format(device.memory_total / (1024**3)) if device.memory_total else 'N/A' }} GB VRAM
                                </small>
                            </div>
                            <span class="badge bg-{{ 'success' if backend.type == 'cuda' else 'danger' if backend.type == 'rocm' else 'warning' }}">
                                {{ backend.type|upper }}
                            </span>
                        </div>
                        {% if device.driver_version %}
                        <div class="mt-2">
                            <small class="text-muted">
                                <i class="bi bi-gear me-1"></i>Driver: {{ device.driver_version }}
                                {% if device.compute_capability %}
                                | Compute: {{ device.compute_capability }}
                                {% endif %}
                            </small>
                        </div>
                        {% endif %}
                        {% if device.memory_total and device.memory_free %}
                        <div class="progress mt-2" style="height: 6px;">
                            <div class="progress-bar bg-info" role="progressbar" 
                                 style="width: {{ ((device.memory_total - device.memory_free) / device.memory_total * 100) }}%">
                            </div>
                        </div>
                        <small class="text-muted">
                            {{ "%.1f"|format((device.memory_total - device.memory_free) / (1024**3)) }} / {{ "%.1f"|format(device.memory_total / (1024**3)) }} GB used
                        </small>
                        {% endif %}
                    </div>
                    {% endfor %}
                    {% endif %}
                    {% endfor %}
                    
                    {% if not gpu_found %}
                    <div class="text-center text-muted py-4">
                        <i class="bi bi-gpu-card display-4"></i>
                        <p class="mt-2">No GPUs detected</p>
                        <small>Using CPU for inference</small>
                    </div>
                    {% endif %}
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Inference Settings -->
<div class="card bg-dark mb-4">
    <div class="card-header">
        <h5 class="mb-0"><i class="bi bi-sliders me-2"></i>Inference Settings ({{ active_backend or 'cpu' }})</h5>
    </div>
    <div class="card-body">
        <div class="row">
            <div class="col-md-3">
                <div class="mb-3">
                    <label class="form-label">GPU Layers</label>
                    <input type="text" class="form-control bg-dark text-light" readonly
                           value="{{ inference_settings.n_gpu_layers }}">
                    <small class="text-muted">-1 = All layers on GPU</small>
                </div>
            </div>
            <div class="col-md-3">
                <div class="mb-3">
                    <label class="form-label">CPU Threads</label>
                    <input type="text" class="form-control bg-dark text-light" readonly
                           value="{{ inference_settings.n_threads }}">
                </div>
            </div>
            <div class="col-md-3">
                <div class="mb-3">
                    <label class="form-label">Batch Size</label>
                    <input type="text" class="form-control bg-dark text-light" readonly
                           value="{{ inference_settings.n_batch }}">
                </div>
            </div>
            <div class="col-md-3">
                <div class="mb-3">
                    <label class="form-label">Memory Mapping</label>
                    <input type="text" class="form-control bg-dark text-light" readonly
                           value="{{ 'Enabled' if inference_settings.use_mmap else 'Disabled' }}">
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Installation Helper -->
<div class="card bg-dark mb-4">
    <div class="card-header">
        <h5 class="mb-0"><i class="bi bi-download me-2"></i>Backend Installation</h5>
    </div>
    <div class="card-body">
        <p class="text-muted">
            To use GPU acceleration, you need to reinstall <code>llama-cpp-python</code> with the appropriate backend.
        </p>
        
        <div class="row">
            <div class="col-md-6">
                <div class="mb-3">
                    <label class="form-label">Select Backend to Install</label>
                    <select class="form-select bg-dark text-light" id="installBackend">
                        {% for backend in profile.backends %}
                        {% if backend.available %}
                        <option value="{{ backend.type }}">{{ backend.name }}</option>
                        {% endif %}
                        {% endfor %}
                    </select>
                </div>
            </div>
            <div class="col-md-4">
                <div class="mb-3">
                    <label class="form-label">Target Environment <span class="badge bg-success">Recommended</span></label>
                    <select class="form-select bg-dark text-light" id="targetVenv">
                        <option value="" disabled>Loading environments...</option>
                        <!-- Will be populated by JavaScript - venvs first, global last -->
                    </select>
                    <small class="text-warning"><i class="bi bi-info-circle me-1"></i>Virtual environments are recommended for isolation</small>
                </div>
            </div>
            <div class="col-md-2">
                <div class="mb-3">
                    <label class="form-label">&nbsp;</label>
                    <div class="d-grid">
                        <button type="button" class="btn btn-success" onclick="installNow()">
                            <i class="bi bi-download me-1"></i>Install
                        </button>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Auto-install option -->
        <div class="alert alert-secondary mt-3">
            <div class="d-flex justify-content-between align-items-center">
                <div>
                    <h6 class="mb-1"><i class="bi bi-magic me-2"></i>Auto-Install</h6>
                    <small class="text-muted">Automatically detect best backend and install llama-cpp-python</small>
                </div>
                <button type="button" class="btn btn-outline-success" onclick="autoInstall()">
                    <i class="bi bi-lightning-charge me-1"></i>Auto-Install
                </button>
            </div>
        </div>
        
        <!-- Create dedicated LLM environment -->
        <div class="alert alert-info mt-3" id="noVenvAlert" style="display: none;">
            <div class="d-flex justify-content-between align-items-center">
                <div>
                    <h6 class="mb-1"><i class="bi bi-plus-circle me-2"></i>Create LLM Environment</h6>
                    <small>No virtual environments found. Create a dedicated environment for LLM work.</small>
                </div>
                <button type="button" class="btn btn-info" onclick="createLLMEnvironment()">
                    <i class="bi bi-folder-plus me-1"></i>Create Environment
                </button>
            </div>
        </div>
        
        <div id="installProgress" class="d-none mt-3">
            <div class="progress" style="height: 25px;">
                <div id="installProgressBar" class="progress-bar progress-bar-striped progress-bar-animated" 
                     role="progressbar" style="width: 0%">0%</div>
            </div>
            <p id="installStatus" class="text-muted mt-2">Starting installation...</p>
        </div>
        
        <!-- Manual command reference -->
        <div class="mt-3">
            <button class="btn btn-sm btn-outline-secondary" type="button" data-bs-toggle="collapse" data-bs-target="#manualCommands">
                <i class="bi bi-terminal me-1"></i>Show Manual Commands
            </button>
            <div class="collapse mt-2" id="manualCommands">
                <div class="card card-body bg-dark">
                    <p class="text-muted small mb-2">Run these commands in your virtual environment:</p>
                    <pre class="bg-dark border p-2 rounded small"><code id="installCommand">pip install llama-cpp-python</code></pre>
                    <button type="button" class="btn btn-sm btn-outline-light" onclick="copyInstallCommand()">
                        <i class="bi bi-clipboard me-1"></i>Copy
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Backend Requirements -->
<div class="card bg-dark">
    <div class="card-header">
        <h5 class="mb-0"><i class="bi bi-info-circle me-2"></i>Backend Requirements</h5>
    </div>
    <div class="card-body">
        <div class="row">
            <div class="col-md-6">
                <h6 class="text-success"><i class="bi bi-gpu-card me-2"></i>CUDA (NVIDIA)</h6>
                <ul class="text-muted small">
                    <li>NVIDIA GPU with CUDA support</li>
                    <li>CUDA Toolkit 11.7+ installed</li>
                    <li>Latest NVIDIA drivers</li>
                    <li>cuBLAS library</li>
                </ul>
                
                <h6 class="text-danger mt-3"><i class="bi bi-gpu-card me-2"></i>ROCm (AMD)</h6>
                <ul class="text-muted small">
                    <li>AMD GPU with ROCm support</li>
                    <li>ROCm 5.0+ installed</li>
                    <li>hipBLAS library</li>
                    <li>Linux only (Windows via WSL2)</li>
                </ul>
            </div>
            <div class="col-md-6">
                <h6 class="text-warning"><i class="bi bi-gpu-card me-2"></i>Vulkan</h6>
                <ul class="text-muted small">
                    <li>Any GPU with Vulkan support</li>
                    <li>Vulkan SDK installed</li>
                    <li>Works on Windows, Linux, macOS</li>
                    <li>Cross-vendor compatibility</li>
                </ul>
                
                <h6 class="text-light mt-3"><i class="bi bi-apple me-2"></i>Metal (Apple)</h6>
                <ul class="text-muted small">
                    <li>Apple Silicon (M1/M2/M3) or AMD GPU</li>
                    <li>macOS 12.0+ (Monterey)</li>
                    <li>Best performance on Apple Silicon</li>
                    <li>Automatic detection</li>
                </ul>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block extra_js %}
<script>
let currentInstallCommand = '';

function detectHardware() {
    showStatus('Detecting hardware...', 'info');
    
    fetch('/llm/api/hardware/detect')
        .then(response => response.json())
        .then(data => {
            showStatus('Hardware detection complete!', 'success');
            setTimeout(() => location.reload(), 1000);
        })
        .catch(error => {
            showStatus('Error detecting hardware: ' + error, 'danger');
        });
}

function selectBackend(backend) {
    fetch('/llm/api/hardware/config', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({backend: backend})
    })
    .then(response => response.json())
    .then(data => {
        if (data.success) {
            showStatus('Backend set to ' + backend.toUpperCase(), 'success');
            setTimeout(() => location.reload(), 1000);
        } else {
            showStatus('Error: ' + data.error, 'danger');
        }
    })
    .catch(error => {
        showStatus('Error: ' + error, 'danger');
    });
}

// Load available virtual environments on page load
document.addEventListener('DOMContentLoaded', function() {
    loadVenvs();
    updateInstallCommand();
});

function loadVenvs() {
    fetch('/llm/api/hardware/venvs')
        .then(response => response.json())
        .then(data => {
            const select = document.getElementById('targetVenv');
            // Clear loading message
            select.innerHTML = '';
            
            // Add virtual environments first (recommended)
            const venvs = data.venvs || [];
            if (venvs.length > 0) {
                const venvGroup = document.createElement('optgroup');
                venvGroup.label = 'ðŸ Virtual Environments (Recommended)';
                
                venvs.forEach((venv, index) => {
                    const option = document.createElement('option');
                    option.value = venv.path;
                    let label = venv.name;
                    if (venv.has_llama_cpp) label += ' âœ“ (installed)';
                    if (venv.is_managed) label += ' [managed]';
                    option.textContent = label;
                    // Select first venv by default
                    if (index === 0) option.selected = true;
                    venvGroup.appendChild(option);
                });
                select.appendChild(venvGroup);
            }
            
            // Add Global as last option (not recommended)
            const globalGroup = document.createElement('optgroup');
            globalGroup.label = 'âš ï¸ System Python (Not Recommended)';
            const globalOption = document.createElement('option');
            globalOption.value = '';
            globalOption.textContent = 'Global Python (may affect other projects)';
            globalGroup.appendChild(globalOption);
            select.appendChild(globalGroup);
            
            // If no venvs found, show a warning and the create button
            if (venvs.length === 0) {
                showStatus('No virtual environments found. Consider creating one first.', 'warning');
                document.getElementById('noVenvAlert').style.display = 'block';
            } else {
                document.getElementById('noVenvAlert').style.display = 'none';
            }
        })
        .catch(error => {
            console.error('Error loading venvs:', error);
            const select = document.getElementById('targetVenv');
            select.innerHTML = '<option value="">Global Python (fallback)</option>';
            document.getElementById('noVenvAlert').style.display = 'block';
        });
}

// Create a dedicated LLM virtual environment
function createLLMEnvironment() {
    const envName = prompt('Enter a name for the LLM environment:', 'llm-env');
    if (!envName) return;
    
    showStatus('Creating virtual environment "' + envName + '"...', 'info');
    
    fetch('/api/environments/create', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            name: envName,
            python_version: null,  // Use system Python
            packages: ['huggingface_hub', 'tqdm']  // Base packages for LLM work
        })
    })
    .then(response => response.json())
    .then(data => {
        if (data.success || data.task_id) {
            if (data.task_id) {
                // Poll for completion
                pollEnvCreation(data.task_id);
            } else {
                showStatus('Environment created! Refreshing...', 'success');
                setTimeout(() => location.reload(), 1500);
            }
        } else {
            showStatus('Error creating environment: ' + (data.error || 'Unknown error'), 'danger');
        }
    })
    .catch(error => {
        showStatus('Error: ' + error, 'danger');
    });
}

function pollEnvCreation(taskId) {
    const eventSource = new EventSource(`/tasks/stream/${taskId}`);
    
    eventSource.onmessage = function(event) {
        const data = JSON.parse(event.data);
        
        document.getElementById('installStatus').textContent = data.message || 'Creating environment...';
        
        if (data.status === 'completed') {
            showStatus('Environment created successfully!', 'success');
            eventSource.close();
            setTimeout(() => location.reload(), 1500);
        } else if (data.status === 'failed') {
            showStatus('Environment creation failed: ' + data.error, 'danger');
            eventSource.close();
        }
    };
    
    eventSource.onerror = function() {
        eventSource.close();
    };
}

function updateInstallCommand() {
    const backend = document.getElementById('installBackend').value;
    
    fetch(`/llm/api/hardware/install-args?backend=${backend}`)
        .then(response => response.json())
        .then(data => {
            currentInstallCommand = data.install_command || 'pip install llama-cpp-python';
            document.getElementById('installCommand').textContent = currentInstallCommand;
        })
        .catch(error => {
            document.getElementById('installCommand').textContent = 'pip install llama-cpp-python';
        });
}

// Update command when backend changes
document.getElementById('installBackend').addEventListener('change', updateInstallCommand);

function copyInstallCommand() {
    navigator.clipboard.writeText(currentInstallCommand).then(() => {
        showStatus('Command copied to clipboard!', 'success');
    });
}

function installNow() {
    const backend = document.getElementById('installBackend').value;
    const venvPath = document.getElementById('targetVenv').value;
    
    startInstallation('/llm/api/hardware/reinstall', {
        backend: backend,
        venv_path: venvPath || null
    });
}

function autoInstall() {
    const venvPath = document.getElementById('targetVenv').value;
    
    startInstallation('/llm/api/hardware/auto-install', {
        venv_path: venvPath || null
    });
}

function startInstallation(url, payload) {
    // Warn if no venv selected
    if (!payload.venv_path) {
        if (!confirm('No virtual environment selected.\n\nInstalling to Global Python may affect other projects.\n\nContinue anyway?')) {
            return;
        }
    }
    
    document.getElementById('installProgress').classList.remove('d-none');
    document.getElementById('installProgressBar').style.width = '0%';
    document.getElementById('installProgressBar').textContent = '0%';
    document.getElementById('installStatus').textContent = 'Starting installation...';
    
    fetch(url, {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify(payload)
    })
    .then(response => response.json())
    .then(data => {
        if (data.success) {
            // Show warning if returned
            if (data.warning) {
                showStatus(data.warning, 'warning');
            }
            pollTaskProgress(data.task_id);
        } else {
            showStatus('Error: ' + data.error, 'danger');
            document.getElementById('installProgress').classList.add('d-none');
        }
    })
    .catch(error => {
        showStatus('Error: ' + error, 'danger');
        document.getElementById('installProgress').classList.add('d-none');
    });
}

function pollTaskProgress(taskId) {
    const eventSource = new EventSource(`/tasks/stream/${taskId}`);
    
    eventSource.onmessage = function(event) {
        const data = JSON.parse(event.data);
        
        document.getElementById('installProgressBar').style.width = data.progress + '%';
        document.getElementById('installProgressBar').textContent = data.progress + '%';
        document.getElementById('installStatus').textContent = data.message || '';
        
        if (data.status === 'completed') {
            showStatus('Installation completed successfully!', 'success');
            eventSource.close();
            setTimeout(() => location.reload(), 2000);
        } else if (data.status === 'failed') {
            showStatus('Installation failed: ' + data.error, 'danger');
            eventSource.close();
            document.getElementById('installProgress').classList.add('d-none');
        }
    };
    
    eventSource.onerror = function() {
        eventSource.close();
    };
}

function showStatus(message, type) {
    const alert = document.getElementById('statusAlert');
    alert.className = `alert alert-${type}`;
    alert.textContent = message;
    alert.classList.remove('d-none');
    
    if (type === 'success' || type === 'info') {
        setTimeout(() => {
            alert.classList.add('d-none');
        }, 5000);
    }
}
</script>
{% endblock %}
