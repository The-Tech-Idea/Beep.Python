<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAITransformerPipeline API - Beep.Python.AI.Transformers</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <link href="../assets/styles.css" rel="stylesheet">
</head>
<body>
    <!-- Mobile Menu Toggle -->
    <button class="mobile-menu-toggle" onclick="toggleSidebar()">
        <i class="bi bi-list"></i>
    </button>

    <!-- Theme Toggle -->
    <button class="theme-toggle" onclick="toggleTheme()" title="Toggle theme">
        <i class="bi bi-sun-fill" id="theme-icon"></i>
    </button>

    <div class="container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <!-- Navigation will be loaded dynamically by navigation.js -->
        </aside>

        <!-- Main Content -->
        <main class="content">
            <div class="content-wrapper">
                <!-- Breadcrumb Navigation -->
                <div class="breadcrumb-nav">
                    <a href="../index.html">Home</a>
                    <span>‚Üí</span>
                    <a href="../index.html#providers">AI Providers</a>
                    <span>‚Üí</span>
                    <span>OpenAI Pipeline</span>
                </div>

                <!-- Page Header -->
                <div class="page-header">
                    <h1><i class="bi bi-circle-fill text-success"></i> OpenAITransformerPipeline Class</h1>
                    <p class="page-subtitle">High-performance transformer pipeline for OpenAI GPT models with advanced features and enterprise capabilities</p>
                </div>

                <!-- Class Info -->
                <div class="class-info">
                    <div class="class-namespace">
                        <strong>Namespace:</strong> Beep.Python.AI.Transformers<br>
                        <strong>Assembly:</strong> Beep.Python.AI.Transformers.dll<br>
                        <strong>Package:</strong> Beep.Python.AI.Transformers
                    </div>
                    <div class="class-implements">
                        <strong>Inherits:</strong> BaseTransformerPipeline<br>
                        <strong>Implements:</strong> ITransformerPipeLine, IDisposable
                    </div>
                </div>

                <!-- Overview Section -->
                <section class="section" id="overview">
                    <h2>üîç Overview</h2>
                    <p>
                        The <strong>OpenAITransformerPipeline</strong> class provides comprehensive integration with OpenAI's GPT models, 
                        including GPT-4, GPT-3.5-turbo, and other OpenAI language models. It offers enterprise-grade features such as 
                        conversation management, token usage tracking, rate limiting, and advanced prompt engineering capabilities.
                    </p>
                    
                    <div class="success">
                        <strong>‚úÖ Supported Models</strong>
                        <ul>
                            <li><strong>GPT-4 Turbo:</strong> Latest GPT-4 model with improved performance</li>
                            <li><strong>GPT-4:</strong> Most capable model for complex reasoning</li>
                            <li><strong>GPT-3.5-turbo:</strong> Fast and efficient for most tasks</li>
                            <li><strong>GPT-3.5-turbo-16k:</strong> Extended context length version</li>
                            <li><strong>Text-Davinci-003:</strong> Legacy completion model</li>
                        </ul>
                    </div>

                    <div class="tip">
                        <strong>üí° Key Features</strong>
                        <ul>
                            <li><strong>Conversation Management:</strong> Built-in chat history and context handling</li>
                            <li><strong>Token Optimization:</strong> Intelligent token counting and optimization</li>
                            <li><strong>Rate Limiting:</strong> Automatic rate limit handling and retry logic</li>
                            <li><strong>Streaming Support:</strong> Real-time response streaming capabilities</li>
                            <li><strong>Function Calling:</strong> Advanced function calling and tool integration</li>
                        </ul>
                    </div>
                </section>

                <!-- Constructor Section -->
                <section class="section" id="constructors">
                    <h2>üèóÔ∏è Constructors</h2>
                    
                    <div class="member">
                        <div class="member-signature">
                            <strong>OpenAITransformerPipeline</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public OpenAITransformerPipeline(
    IPythonRunTimeManager pythonRunTimeManager,
    IPythonCodeExecuteManager executeManager,
    OpenAIConnectionConfig connectionConfig)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Initializes a new instance of the OpenAITransformerPipeline with the specified runtime manager, execution manager, and OpenAI connection configuration.</p>
                        </div>
                    </div>
                </section>

                <!-- Properties Section -->
                <section class="section" id="properties">
                    <h2>üìã Properties</h2>

                    <div class="member">
                        <div class="member-signature">
                            <strong>ConnectionConfig</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public OpenAIConnectionConfig ConnectionConfig { get; }</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Gets the OpenAI connection configuration including API key, organization ID, and request settings.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>CurrentModel</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public string CurrentModel { get; private set; }</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Gets the currently loaded OpenAI model name (e.g., "gpt-4", "gpt-3.5-turbo").</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>TokenUsage</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public TokenUsageInfo TokenUsage { get; }</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Gets detailed token usage statistics including prompt tokens, completion tokens, and total tokens consumed.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>ConversationHistory</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public List<ChatMessage> ConversationHistory { get; }</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Gets the current conversation history for chat-based interactions with context preservation.</p>
                        </div>
                    </div>
                </section>

                <!-- Methods Section -->
                <section class="section" id="methods">
                    <h2>‚ö° Methods</h2>

                    <h3>Text Generation Methods</h3>

                    <div class="member">
                        <div class="member-signature">
                            <strong>GenerateTextAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public override async Task<TransformerResponse<string>> GenerateTextAsync(
    string prompt,
    TextGenerationParameters parameters = null)

// Overload with conversation context
public async Task<TransformerResponse<string>> GenerateTextAsync(
    string prompt,
    List<ChatMessage> conversationHistory,
    TextGenerationParameters parameters = null)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Generates text using the loaded OpenAI model with optional conversation context and generation parameters.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>GenerateStreamingTextAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public async IAsyncEnumerable<string> GenerateStreamingTextAsync(
    string prompt,
    TextGenerationParameters parameters = null)

// With progress callback
public async Task GenerateStreamingTextAsync(
    string prompt,
    Action<string> onTokenReceived,
    TextGenerationParameters parameters = null)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Generates text with real-time streaming, yielding tokens as they are received from OpenAI's API.</p>
                        </div>
                    </div>

                    <h3>Chat and Conversation Methods</h3>

                    <div class="member">
                        <div class="member-signature">
                            <strong>SendChatMessageAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public async Task<TransformerResponse<string>> SendChatMessageAsync(
    string message,
    string role = "user",
    TextGenerationParameters parameters = null)

// With system message
public async Task<TransformerResponse<string>> SendChatMessageAsync(
    string message,
    string systemMessage,
    TextGenerationParameters parameters = null)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Sends a chat message and maintains conversation context automatically.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>ClearConversationHistory</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public void ClearConversationHistory()

// Clear with system message retention
public void ClearConversationHistory(bool retainSystemMessage = false)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Clears the conversation history, optionally retaining system messages.</p>
                        </div>
                    </div>

                    <h3>Function Calling Methods</h3>

                    <div class="member">
                        <div class="member-signature">
                            <strong>CallFunctionAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public async Task<TransformerResponse<string>> CallFunctionAsync(
    string prompt,
    List<FunctionDefinition> availableFunctions,
    TextGenerationParameters parameters = null)

// With automatic function execution
public async Task<TransformerResponse<string>> CallFunctionWithExecutionAsync(
    string prompt,
    Dictionary<string, Func<string, Task<string>>> functionHandlers,
    TextGenerationParameters parameters = null)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Enables function calling capabilities with OpenAI models, allowing the AI to call predefined functions.</p>
                        </div>
                    </div>

                    <h3>Model Management Methods</h3>

                    <div class="member">
                        <div class="member-signature">
                            <strong>LoadModelAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public override async Task<bool> LoadModelAsync(
    TransformerModelInfo modelInfo,
    TransformerTask taskType)

// With validation
public async Task<bool> LoadModelAsync(
    TransformerModelInfo modelInfo,
    TransformerTask taskType,
    bool validateModel = true)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Loads and validates the specified OpenAI model for the given task type.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>GetAvailableModelsAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public async Task<List<string>> GetAvailableModelsAsync()

// With model details
public async Task<List<ModelInfo>> GetAvailableModelsWithDetailsAsync()</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Retrieves the list of available OpenAI models for the current account.</p>
                        </div>
                    </div>

                    <h3>Utility Methods</h3>

                    <div class="member">
                        <div class="member-signature">
                            <strong>EstimateTokenCountAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public async Task<int> EstimateTokenCountAsync(string text)

// For conversation
public async Task<int> EstimateConversationTokenCountAsync(
    List<ChatMessage> messages)</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Estimates the token count for the given text or conversation, useful for cost optimization.</p>
                        </div>
                    </div>

                    <div class="member">
                        <div class="member-signature">
                            <strong>TestConnectionAsync</strong>
                        </div>
                        <div class="code-example">
                            <pre><code class="language-csharp">public override async Task<bool> TestConnectionAsync()

// With detailed diagnostics
public async Task<ConnectionTestResult> TestConnectionWithDiagnosticsAsync()</code></pre>
                        </div>
                        <div class="member-description">
                            <p>Tests the connection to OpenAI's API and validates the API key and configuration.</p>
                        </div>
                    </div>
                </section>

                <!-- Usage Examples Section -->
                <section class="section" id="examples">
                    <h2>üíª Usage Examples</h2>

                    <h3>Basic Text Generation</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">// Initialize OpenAI pipeline
var config = new OpenAIConnectionConfig
{
    ApiKey = "your-openai-api-key",
    OrganizationId = "your-org-id", // Optional
    TimeoutSeconds = 60,
    MaxRetries = 3
};

var pipeline = new OpenAITransformerPipeline(runtimeManager, executeManager, config);

// Load GPT-4 model
await pipeline.LoadModelAsync(
    new TransformerModelInfo 
    { 
        Name = "gpt-4", 
        Source = TransformerModelSource.OpenAI 
    },
    TransformerTask.TextGeneration);

// Generate text
var result = await pipeline.GenerateTextAsync(
    "Explain quantum computing in simple terms",
    new TextGenerationParameters
    {
        MaxLength = 500,
        Temperature = 0.7,
        TopP = 0.9
    });

if (result.Success)
{
    Console.WriteLine($"Generated text: {result.Data}");
    Console.WriteLine($"Tokens used: {pipeline.TokenUsage.TotalTokens}");
}
else
{
    Console.WriteLine($"Error: {result.ErrorMessage}");
}</code></pre>
                    </div>

                    <h3>Chat Conversation</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">// Initialize chat session
var pipeline = new OpenAITransformerPipeline(runtimeManager, executeManager, config);
await pipeline.LoadModelAsync(
    new TransformerModelInfo { Name = "gpt-3.5-turbo", Source = TransformerModelSource.OpenAI },
    TransformerTask.Conversation);

// Set system message
await pipeline.SendChatMessageAsync(
    "You are a helpful AI assistant specialized in programming.",
    "system");

// User conversation
var response1 = await pipeline.SendChatMessageAsync(
    "How do I implement a binary search algorithm in C#?");

Console.WriteLine($"AI: {response1.Data}");

// Continue conversation with context
var response2 = await pipeline.SendChatMessageAsync(
    "Can you show me a recursive version?");

Console.WriteLine($"AI: {response2.Data}");

// View conversation history
foreach (var message in pipeline.ConversationHistory)
{
    Console.WriteLine($"{message.Role}: {message.Content}");
}</code></pre>
                    </div>

                    <h3>Streaming Text Generation</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">// Set up streaming with real-time output
var pipeline = new OpenAITransformerPipeline(runtimeManager, executeManager, config);
await pipeline.LoadModelAsync(
    new TransformerModelInfo { Name = "gpt-4", Source = TransformerModelSource.OpenAI },
    TransformerTask.TextGeneration);

Console.Write("AI Response: ");

// Stream response token by token
await pipeline.GenerateStreamingTextAsync(
    "Write a short story about a robot learning to paint",
    token => 
    {
        Console.Write(token);
        Console.Out.Flush();
    },
    new TextGenerationParameters
    {
        Temperature = 0.8,
        MaxLength = 1000
    });

Console.WriteLine("\n\nStreaming completed.");</code></pre>
                    </div>

                    <h3>Function Calling</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">// Define available functions
var weatherFunction = new FunctionDefinition
{
    Name = "get_weather",
    Description = "Get current weather for a location",
    Parameters = new
    {
        type = "object",
        properties = new
        {
            location = new { type = "string", description = "City name" },
            unit = new { type = "string", @enum = new[] { "celsius", "fahrenheit" } }
        },
        required = new[] { "location" }
    }
};

var calculatorFunction = new FunctionDefinition
{
    Name = "calculate",
    Description = "Perform mathematical calculations",
    Parameters = new
    {
        type = "object",
        properties = new
        {
            expression = new { type = "string", description = "Mathematical expression" }
        },
        required = new[] { "expression" }
    }
};

// Set up function handlers
var functionHandlers = new Dictionary<string, Func<string, Task<string>>>
{
    ["get_weather"] = async (args) =>
    {
        var weatherArgs = JsonSerializer.Deserialize<WeatherArgs>(args);
        // Call actual weather API
        return await GetWeatherAsync(weatherArgs.Location, weatherArgs.Unit);
    },
    
    ["calculate"] = async (args) =>
    {
        var calcArgs = JsonSerializer.Deserialize<CalculatorArgs>(args);
        // Perform calculation
        return EvaluateExpression(calcArgs.Expression).ToString();
    }
};

// Use function calling
var result = await pipeline.CallFunctionWithExecutionAsync(
    "What's the weather like in New York and what's 15 * 24?",
    functionHandlers,
    new TextGenerationParameters { Temperature = 0.1 });

Console.WriteLine($"AI Response: {result.Data}");</code></pre>
                    </div>

                    <h3>Error Handling and Retry Logic</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">public async Task<string> GenerateTextWithRetry(string prompt, int maxRetries = 3)
{
    var pipeline = new OpenAITransformerPipeline(runtimeManager, executeManager, config);
    
    for (int attempt = 1; attempt <= maxRetries; attempt++)
    {
        try
        {
            var result = await pipeline.GenerateTextAsync(prompt);
            
            if (result.Success)
            {
                return result.Data;
            }
            
            // Handle specific OpenAI errors
            if (result.ErrorMessage?.Contains("rate_limit_exceeded") == true)
            {
                var delaySeconds = Math.Pow(2, attempt); // Exponential backoff
                Console.WriteLine($"Rate limit hit, waiting {delaySeconds} seconds...");
                await Task.Delay(TimeSpan.FromSeconds(delaySeconds));
                continue;
            }
            
            if (result.ErrorMessage?.Contains("insufficient_quota") == true)
            {
                throw new InvalidOperationException("OpenAI quota exceeded");
            }
            
            Console.WriteLine($"Attempt {attempt} failed: {result.ErrorMessage}");
        }
        catch (Exception ex) when (attempt < maxRetries)
        {
            Console.WriteLine($"Attempt {attempt} threw exception: {ex.Message}");
            await Task.Delay(TimeSpan.FromSeconds(attempt)); // Linear backoff
        }
    }
    
    throw new InvalidOperationException($"Failed to generate text after {maxRetries} attempts");
}</code></pre>
                    </div>
                </section>

                <!-- Configuration Section -->
                <section class="section" id="configuration">
                    <h2>‚öôÔ∏è Configuration Options</h2>

                    <h3>OpenAIConnectionConfig Properties</h3>
                    <div class="code-example">
                        <pre><code class="language-csharp">public class OpenAIConnectionConfig : TransformerConnectionConfig
{
    // Authentication
    public string ApiKey { get; set; }
    public string OrganizationId { get; set; } // Optional

    // Request settings
    public int TimeoutSeconds { get; set; } = 60;
    public int MaxRetries { get; set; } = 3;
    public double RetryDelayMultiplier { get; set; } = 2.0;

    // Rate limiting
    public int RequestsPerMinute { get; set; } = 3500;
    public int TokensPerMinute { get; set; } = 90000;

    // Model defaults
    public string DefaultModel { get; set; } = "gpt-3.5-turbo";
    public double DefaultTemperature { get; set; } = 0.7;
    public int DefaultMaxTokens { get; set; } = 1000;

    // Advanced options
    public bool EnableFunctionCalling { get; set; } = true;
    public bool EnableStreaming { get; set; } = true;
    public bool LogRequests { get; set; } = false;
}</code></pre>
                    </div>

                    <h3>Environment Configuration</h3>
                    <div class="code-example">
                        <pre><code class="language-bash"># Environment variables
OPENAI_API_KEY=your-api-key-here
OPENAI_ORGANIZATION=your-org-id-here
OPENAI_DEFAULT_MODEL=gpt-4
OPENAI_TIMEOUT_SECONDS=60
OPENAI_MAX_RETRIES=3</code></pre>
                    </div>

                    <div class="code-example">
                        <h4>Configuration from Environment</h4>
                        <pre><code class="language-csharp">var config = new OpenAIConnectionConfig
{
    ApiKey = Environment.GetEnvironmentVariable("OPENAI_API_KEY"),
    OrganizationId = Environment.GetEnvironmentVariable("OPENAI_ORGANIZATION"),
    DefaultModel = Environment.GetEnvironmentVariable("OPENAI_DEFAULT_MODEL") ?? "gpt-3.5-turbo",
    TimeoutSeconds = int.Parse(Environment.GetEnvironmentVariable("OPENAI_TIMEOUT_SECONDS") ?? "60"),
    MaxRetries = int.Parse(Environment.GetEnvironmentVariable("OPENAI_MAX_RETRIES") ?? "3")
};</code></pre>
                    </div>
                </section>

                <!-- Best Practices Section -->
                <section class="section" id="best-practices">
                    <h2>üéØ Best Practices</h2>

                    <div class="success">
                        <strong>‚úÖ Performance Optimization</strong>
                        <ul>
                            <li>Use GPT-3.5-turbo for most tasks; reserve GPT-4 for complex reasoning</li>
                            <li>Optimize prompts to reduce token usage and improve response quality</li>
                            <li>Implement caching for repeated queries to reduce API costs</li>
                            <li>Use streaming for long responses to improve user experience</li>
                            <li>Monitor token usage and implement usage limits</li>
                        </ul>
                    </div>

                    <div class="warning">
                        <strong>‚ö†Ô∏è Cost Management</strong>
                        <ul>
                            <li>Always set reasonable max_tokens limits to prevent runaway costs</li>
                            <li>Use conversation trimming to manage context length</li>
                            <li>Monitor API usage and set up billing alerts</li>
                            <li>Consider using fine-tuned models for specific domains</li>
                            <li>Implement request queuing during high-traffic periods</li>
                        </ul>
                    </div>

                    <div class="note">
                        <strong>üìã Quality Assurance</strong>
                        <ul>
                            <li>Validate all outputs, especially for production applications</li>
                            <li>Implement content filtering for user-facing applications</li>
                            <li>Use system messages to guide model behavior consistently</li>
                            <li>Test with various temperature settings to find optimal balance</li>
                            <li>Implement fact-checking for factual claims when necessary</li>
                        </ul>
                    </div>
                </section>

                <!-- Related Classes -->
                <section class="section" id="related">
                    <h2>üîó Related Classes</h2>
                    <ul class="member-list">
                        <li>
                            <div class="member-name">BaseTransformerPipeline</div>
                            <div class="member-type">Abstract Class</div>
                            <div class="member-desc">Base implementation with common pipeline functionality</div>
                        </li>
                        <li>
                            <div class="member-name">OpenAIConnectionConfig</div>
                            <div class="member-type">Configuration Class</div>
                            <div class="member-desc">Configuration options for OpenAI integration</div>
                        </li>
                        <li>
                            <div class="member-name">AzureTransformerPipeline</div>
                            <div class="member-type">Pipeline Class</div>
                            <div class="member-desc">Azure OpenAI pipeline implementation</div>
                        </li>
                        <li>
                            <div class="member-name">ChatMessage</div>
                            <div class="member-type">Data Class</div>
                            <div class="member-desc">Represents a message in a chat conversation</div>
                        </li>
                    </ul>
                </section>

                <!-- Navigation Links -->
                <div class="nav-links">
                    <a href="HuggingFaceTransformerPipeline.html" class="btn-beep">
                        <i class="bi bi-arrow-left"></i> HuggingFace Pipeline
                    </a>
                    <a href="AzureTransformerPipeline.html" class="btn-beep">
                        <i class="bi bi-arrow-right"></i> Azure Pipeline
                    </a>
                </div>

                <!-- Footer -->
                <footer class="documentation-footer">
                    <div class="footer-content">
                        <div class="footer-copyright">
                            <p>&copy; 2024 The Tech Idea - Beep.Python.AI.Transformers API Documentation</p>
                        </div>
                        <div class="footer-links">
                            <a href="../index.html">Home</a>
                            <a href="ITransformerPipeLine.html">ITransformerPipeLine</a>
                            <a href="TransformerPipelineFactory.html">Pipeline Factory</a>
                        </div>
                    </div>
                </footer>
            </div>
        </main>
    </div>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="../assets/navigation.js"></script>
</body>
</html>